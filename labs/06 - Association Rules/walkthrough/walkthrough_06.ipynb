{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/michalis0/Business-Intelligence-and-Analytics/blob/master/labs/06%20-%20Association%20Rules/walkthrough/walkthrough_06.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg_TyptX13wN"
      },
      "source": [
        "# Mining Association Rules\n",
        "In this week's lab, we are going to mine association rules using the Python library `mlxtend`. You can install the library using pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgD9mwNu13wP"
      },
      "outputs": [],
      "source": [
        "!pip install mlxtend  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "J_AQrWRv13wZ"
      },
      "source": [
        "## Hands-On\n",
        "Before starting to code let's practice with a toy example.\n",
        "Calculate support and confidence for the following association rules given the shopping receipts database below.\n",
        "<br><img src=\"https://github.com/michalis0/Business-Intelligence-and-Analytics/raw/master/labs/06%20-%20Association%20Rules/img/association_rules.png\" width=\"500\" style=\"float: left\"><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm8Vp8V213wc"
      },
      "source": [
        "Answer:\n",
        "```\n",
        "{Water} => {Juice}\n",
        "    Support = \n",
        "    Confidence = \n",
        "    \n",
        "{Juice} => {Water}\n",
        "    Support = \n",
        "    Confidence = \n",
        "    \n",
        "{Milk} => {Bread}\n",
        "    Support = \n",
        "    Confidence = \n",
        "    \n",
        "{Juice, Beer} => {Water}\n",
        "    Support = \n",
        "    Confidence = \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxPhhXOv13we"
      },
      "source": [
        "Suppose that we have a support threshold of 40% and confidence threshold of 75%. Which rules are most interesting? Why?<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvDhXW7113wf"
      },
      "source": [
        "Do you think using only the support and confidence measures is enough to identify a rule as intersing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOBhEI_T13wg"
      },
      "source": [
        "## Apriori algorithm\n",
        "\n",
        "We will use the apriori algorithm to mine the frequent itemsets. The `mlxtend` library has an implementation of this algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCVAa4c713wh"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "godcn8Ye13wn"
      },
      "source": [
        "## Load data\n",
        "The dataset we are going to use is a synthetic dataset. It contains the purchases of customers. You can find the source of the dataset [here](https://gist.github.com/Harsh-Git-Hub/2979ec48043928ad9033d8469928e751)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jXeJ9YD913wo",
        "outputId": "2e5e7081-9b96-4dd4-cd7f-eb0c6e83b1eb"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('https://media.githubusercontent.com/media/michalis0/Business-Intelligence-and-Analytics/master/data/retail_dataset.csv', sep=',')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFxZsGIREij2",
        "outputId": "21305b99-952c-42fa-e2e4-f794f47264ec"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faU3cGvf13w0"
      },
      "source": [
        "Each row of the dataset represents items that were purchased together on the same day at the same store.The dataset is a sparse dataset as relatively high percentage of data is NA or NaN or equivalent.\n",
        "These NaNs make it hard to read the table. Let’s find out how many unique items are actually there in the table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xfKe60813w1",
        "outputId": "85c0ba75-69e6-48a1-a785-a62924385e76"
      },
      "outputs": [],
      "source": [
        "items = (df['0'].unique())\n",
        "items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q698poU13w6"
      },
      "source": [
        "## Data Preprocessing\n",
        "To make use of the apriori module given by `mlxtend` library, we need to convert the dataset according to it’s liking. apriori module requires a dataframe that has either 0 and 1 or True and False as data. The data we have is all string (name of items), we need to One Hot Encode the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18xj2hP913w7"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "for ind, row in df.iterrows():\n",
        "    transaction = []\n",
        "    for item in row: \n",
        "        # check if item is NaN\n",
        "        if item == item:\n",
        "            transaction.append(item)\n",
        "    dataset.append(transaction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghaWb7NuEZlq",
        "outputId": "351f8a57-7b05-42d7-e0e5-3242d64c9854"
      },
      "outputs": [],
      "source": [
        "type(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SimYUCG1Edds",
        "outputId": "353ed214-146c-4aa2-8617-57fa2e3e6551"
      },
      "outputs": [],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc62cKLx13w_"
      },
      "source": [
        "Next using the `TransactionEncoder` we can transform the transactions to True or False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bAy_WipF13w_",
        "outputId": "8fc9cd94-8876-4538-da6d-05c135594f18"
      },
      "outputs": [],
      "source": [
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(dataset).transform(dataset)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3mdzNHh13xE"
      },
      "source": [
        "## Applying Apriori\n",
        "Now we use the apriori module from mlxtend library to find the frequent itemsets. Before that, let's look at some parameters of this module:\n",
        "\n",
        "- `df` : One-Hot-Encoded DataFrame or DataFrame that has 0 and 1 or True and False as values\n",
        "- `min_support` : Floating point value between 0 and 1 that indicates the minimum support required for an itemset to be selected.\n",
        "- `use_colnames` : This allows to preserve column names for itemset making it more readable.\n",
        "- `max_len` : Max length of itemset generated. If not set, all possible lengths are evaluated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "2S2JrOuf13xE",
        "outputId": "e333ba49-db71-49fd-94f0-9d764cc15c62"
      },
      "outputs": [],
      "source": [
        "freq_items = apriori(df, min_support=0.2, use_colnames=True)\n",
        "freq_items.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk_SBVY913xL"
      },
      "source": [
        "## Mining Association Rules\n",
        "Frequent if-then associations called association rules which consists of an antecedent (if) and a consequent (then) in other words `{antecedent} => {consequent}`. The metric can be set to confidence, lift, support, leverage and conviction. In the example below we use the confidence metric with a threshold of __0.6__. This means that we are selecting the rules with a confidence more than __0.6__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "2pAnlteO13xL",
        "outputId": "fa048af6-0fd4-442e-a51d-0cc4a7bf2d72"
      },
      "outputs": [],
      "source": [
        "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.6)\n",
        "rules.sort_values(by='lift', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm5wI0J-13xQ"
      },
      "source": [
        "The `rules` dataframe contains all the association rules that we determined as interesting. What do you think? Are they really interesting? What does the __lift__ metric tells you?\n",
        "\n",
        "Try to generate the above rules again but now with a smaller threshold for confidence, say $0.4$. What do you think about the rules now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOgj7xo713xR",
        "outputId": "e8a1d839-329b-4570-e1bc-40af700b5af2"
      },
      "outputs": [],
      "source": [
        "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.4)\n",
        "rules[rules[\"lift\"] < 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D6z28oB13xU"
      },
      "source": [
        "## Exercise: your turn!\n",
        "Let's try with a more real and bigger dataset. Load the `Groceries.csv` file and try to find association rules Using the __confidence__ metric and a support threshold of __0.001__ and confidence threshold of __0.05__. \n",
        "\n",
        "Check out ther rules you have found that have \"bottled beer\" as antecedant. Are all of these rules interesting?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ9vNCeY13xW"
      },
      "source": [
        "### Load the data\n",
        "First, download the `groceries.csv` file from the GitHub repository and if working in Colab, upload it to the runtime files(Business-Intelligence-and-Analytics-->data-->[Groceries.csv](https://github.com/michalis0/Business-Intelligence-and-Analytics/blob/master/data/Groceries.csv)-->Download the file-->go on colab--> on the left side of colab click on files and import your file \"Groceries.csv\" there). Notice that this is not a proper csv file and there are different number of values in each row. So you have to read the file manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6YCbW3h13xW"
      },
      "outputs": [],
      "source": [
        "with open('Groceries.csv', 'r') as f:\n",
        "    dataset = []\n",
        "    for line in f:\n",
        "        transaction = []\n",
        "        row = line.rstrip('\\n').split(',')\n",
        "        for item in row:\n",
        "            transaction.append(item)\n",
        "        dataset.append(transaction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LN_ImnA13xc"
      },
      "outputs": [],
      "source": [
        "# create the one_hot encoded dataframe with TransactionEncoder()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo62rpm013xf"
      },
      "outputs": [],
      "source": [
        "# find the frequent itemsets with  min_support=0.001, max_len=2\n",
        "\n",
        "\n",
        "# find the association rules with metric='confidence' and min_threshold=0.05\n",
        "\n",
        "\n",
        "# extract rules with 'bottled beer' as antecedents \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MX0tZB-W13xj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "author": "Thai Pangsakulyanont",
    "colab": {
      "include_colab_link": true,
      "name": "AssociationRules.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
