{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/michalis0/Business-Intelligence-and-Analytics/blob/e58bf1036e1aa93b99f9fddba2ec17ca44a94a9e/labs/11%20-%20Classification%201/Exercises/exercise_classification.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 align=\"center\"> EXERCISES 9</h1>\n",
        "\n",
        "<div>\n",
        "<td> \n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Logo_Universit%C3%A9_de_Lausanne.svg/2000px-Logo_Universit%C3%A9_de_Lausanne.svg.png\" style=\"padding-right:10px;width:240px;float:left\"/></td>\n",
        "<h2 style=\"white-space: nowrap\">Business Intelligence and Analytics</h2></td>\n",
        "<hr style=\"clear:both\">\n",
        "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1BSf8GX2sQd"
      },
      "source": [
        "# Classification\n",
        "\n",
        "## Logistic Regression \n",
        "\n",
        "In this lab we will explore logistic regression which is a well known method for classification problems. We will work with a hearth disease data-set, and we will try to predict whether the patient has a heart disease or not.\n",
        "\n",
        "\n",
        "![Heart](https://img.webmd.com/dtmcms/live/webmd/consumer_assets/site_images/articles/health_tools/how_heart_disease_affects_your_body_slideshow/493ss_thinkstock_rf_heart_anatomy_illustration.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D9mQhcj2sQe",
        "outputId": "7213db1d-78a4-4295-b9c2-8f32bebaee68"
      },
      "outputs": [],
      "source": [
        "# Imports \n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import collections  as mc\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "sns.set_style(\"white\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1CKWYwc2sQh"
      },
      "outputs": [],
      "source": [
        "# set random seed \n",
        "np.random.seed = 72"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTVsCvCv2sQl"
      },
      "source": [
        "### Load data\n",
        "\n",
        "We will start with the hear disease data-set. Here's a description of the attributes in the data-set:\n",
        "\n",
        "1. `age`\n",
        "2. `sex`\n",
        "3. `cp`: chest pain type (4 values)\n",
        "4. `trestbps`: resting blood pressure\n",
        "5. `chol`: serum cholestoral in mg/dl\n",
        "6. `fbs`: fasting blood sugar > 120 mg/dl\n",
        "7. `restecg`: resting electrocardiographic results (values 0,1,2)\n",
        "8. `thalach`: maximum heart rate achieved\n",
        "9. `exang`: exercise induced angina\n",
        "10. `target`: presence of heart disease (1), absence of heart disease(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5trH0DXt2sQl",
        "outputId": "4f4b5134-bbf2-4bb2-99e6-643c6345ff24"
      },
      "outputs": [],
      "source": [
        "#Load data\n",
        "# data-set: heart.csv\n",
        "url = \"https://media.githubusercontent.com/media/michalis0/Business-Intelligence-and-Analytics/master/data/heart.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFUEig7y2sQp"
      },
      "outputs": [],
      "source": [
        "# sklearn imports \n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BLOy4W32sQt"
      },
      "source": [
        "### Simple Logistic Regression\n",
        "\n",
        "Let's start with only 2 features to predict heart diseases: age and maximum heart rate achieved (`thalach`). Define your features and target variable. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki6QRs6t2sQu"
      },
      "outputs": [],
      "source": [
        "X = 'Your Code Here'\n",
        "y = 'Your Code Here'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjPq4TjY4I-C"
      },
      "source": [
        "Split your data set into train and test subsets. \n",
        "\n",
        "Use ` test_size=0.3, random_state=72` as parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFO3lzpD2NKN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split   \n",
        "\n",
        "# Your Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNpdZRMv2sQ0"
      },
      "source": [
        "#### Standardizing\n",
        "\n",
        "When you do standardization (or any other modification) to the training data, you have to apply the same modifications to the test data as well. Otherwise your test accuracy would be non-sense.\n",
        "\n",
        "Here we apply the same standardisation to test data, which means that we normalize the test data with mean and standard deviation from the train data.\n",
        "\n",
        "Use *StandardScaler()* for normalization. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3h50T5Lh2sQ1"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7a6TZVV3ZZi"
      },
      "source": [
        "Apply the standardization to your train and test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGjKow5Y2sQ4"
      },
      "outputs": [],
      "source": [
        "# Transform the train and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw5rbTEV3hnH"
      },
      "source": [
        "Define your model. Try to use a logistic regression with cross validation using theses parameters : `solver='lbfgs', cv=10, max_iter=100`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nExvGYiR2sQ7"
      },
      "outputs": [],
      "source": [
        "# logistic regression with 10 fold cross validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyxTAXGs3nez"
      },
      "source": [
        "Fit your model now using the train set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9WckoiSD8kv"
      },
      "outputs": [],
      "source": [
        "# Fit your model on the train set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCu8nkWe3sXG"
      },
      "source": [
        "Compare your train and test accuracy for your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YK9xRp6CIyP"
      },
      "outputs": [],
      "source": [
        "# train accuracy with CV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4V2KZ7XTCNNK"
      },
      "outputs": [],
      "source": [
        "# test accuracy with CV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJGMIl1ynW5V"
      },
      "source": [
        "Have a look at the class distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv5YrDBGnaB7"
      },
      "outputs": [],
      "source": [
        "#Create a bar chart to represent the distribution of the target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYS-bFxJrZNw"
      },
      "source": [
        "Compute the baserate.\n",
        "\n",
        "$$Base rate = \\frac{Most\\_frequent\\_class}{Total\\_observations}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFsMa1m2r7pj"
      },
      "outputs": [],
      "source": [
        "#Compute the base rate\n",
        "\n",
        "nbr_heart_disease = # Your code here\n",
        "print(f'There are {'Your Code Here'} observations with heart diseases')\n",
        "\n",
        "nbr_no_heart_disease = # Your code here\n",
        "print(f'There are {'Youe code HEre'} observations with no heart diseases')\n",
        "\n",
        "base_rate = # Your code here\n",
        "print(f'The Base rate is : {'your code here'}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjgp2sfVrb8B"
      },
      "source": [
        "Use the confusion_matrix module to show the confusion matrix of the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DsK5wpLrfSt"
      },
      "outputs": [],
      "source": [
        "#Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Create the confusion matrix of the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH8ULHCQmv0b"
      },
      "source": [
        "Plot the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUMb12IdmxtV"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix using sns.heatmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Try to predict the class and probability of correct classification for `patient 1` `Age = 40, Thalach = 180` and `patient 2` `Age = 70, Thalach = 100`\n",
        "\n",
        "**This part accounts for the first question of the quizz.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a data frame with our two suspects\n",
        "features = # Your code here\n",
        "\n",
        "# Scale the values\n",
        "features = # Your code here\n",
        "\n",
        "# Create the predictions\n",
        "predictions_q1 = # Your code here\n",
        "print(f'The first patient has a prediction of {'Your Code Here'} and the second one {'Your code Here'}')\n",
        "\n",
        "#Create the probabilities of each prediction\n",
        "proba_q1 =  # Your code here\n",
        "\n",
        "print(f'The probabilities of the first patient are {'Your Code Here'} and {'Your Code Here'} for the second ')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1CT6zVb2sRM"
      },
      "source": [
        "### Decision boundary\n",
        "\n",
        "As we used only two features for classification, we can observe the linear decision boundary made by the logistic regression in a 2D plot. You can also observe the mis-classified training points in this plot. Let's plot the decision boundary for the model with cross validation. \n",
        "\n",
        "Use theses parameters for the Logistic Regression model `solver='lbfgs', cv=10, max_iter=100`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Decision boundary\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the model\n",
        "\n",
        "\n",
        "#Fit the model on X and y (use all the available data withhout spliting)\n",
        "\n",
        "\n",
        "\n",
        "plt.scatter('Your code here', 'Your code here', c='Your code Here', edgecolors='k', cmap=plt.cm.Paired)\n",
        "ax = plt.gca()\n",
        "x_vals = 'Your code here'\n",
        "y_vals = 'Your code here'\n",
        "plt.plot(x_vals, y_vals, '--', c=\"red\")\n",
        "\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Maximum hearth rate')\n",
        "\n",
        "\n",
        "plt.title('Decision boundary for classification model with cross-validation using two features')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRpOrur22sRV"
      },
      "source": [
        "Now let's try more numerical features and see if the accuracy improuves.\n",
        "We will use now `\"age\", \"thalach\", \"trestbps\" and \"chol\"`. \n",
        "Define your features and your target variable. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDnaUYF92sRV"
      },
      "outputs": [],
      "source": [
        "X = # Your Code here\n",
        "y = # Your Code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q09jUP34hme"
      },
      "source": [
        "Split your data set into train and test subsets. ` test_size=0.3, random_state=72`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g55iCbL2sRY"
      },
      "outputs": [],
      "source": [
        "# Split the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsuD0tPc4ugm"
      },
      "source": [
        "Standardize your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9ScYZRs2sRd"
      },
      "outputs": [],
      "source": [
        "# Create the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9Y0TMkp2sRg"
      },
      "outputs": [],
      "source": [
        "#Apply normalization to the training and testing set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQOpg_A04zNw"
      },
      "source": [
        "Fit your model using the train data. Let's use the logistic regression with cross validation here. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MMBMLJZ2sRk"
      },
      "outputs": [],
      "source": [
        "# Fit the regression model on the training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEOw7KN8421R"
      },
      "source": [
        "Compare your train and test accurary. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwPGNVyx2sRp"
      },
      "outputs": [],
      "source": [
        "# train accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2cIMQD-2sRs"
      },
      "outputs": [],
      "source": [
        "# test accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceS90RCBoqws"
      },
      "source": [
        "Finally, show the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn-EZaVmD0of"
      },
      "outputs": [],
      "source": [
        "#Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Create the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.heatmap(pd.DataFrame('Your Code Here'), annot=True, cmap='Blues', fmt='.4g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Question two: How did the train and test accuracy change when adding theses additionals features?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Exercises_Classification_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0cc462c96df3621bcc58e01fadcdf9264a069c5c4bbf07201077bb349d3c6bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
