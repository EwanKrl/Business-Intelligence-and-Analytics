{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/michalis0/Business-Intelligence-and-Analytics/blob/master/labs/07%20-%20Regression/walkthrough/walkthrough_07.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 align=\"center\"> WALKTHROUGH 7</h1>\n",
        "\n",
        "<div>\n",
        "<td> \n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Logo_Universit%C3%A9_de_Lausanne.svg/2000px-Logo_Universit%C3%A9_de_Lausanne.svg.png\" style=\"padding-right:10px;width:240px;float:left\"/></td>\n",
        "<h2 style=\"white-space: nowrap\">Business Intelligence and Analytics</h2></td>\n",
        "<hr style=\"clear:both\">\n",
        "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
        "\n",
        "</div>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "u461z_Wk-K-P"
      },
      "source": [
        "Regression is to relate input variables to the output variable, to either predict outputs for new inputs and/or to understand the effect of the input on the output. In prediction, we wish to predict the output for a new input vector. In interpretation, we wish to understand the effect of inputs on output.\n",
        "\n",
        "For both goals, we need to find a function that approximates the output “well enough” given some inputs:\n",
        "\n",
        "$$y_n =f(\\boldsymbol{x_{n}})$$\n",
        "\n",
        "In python, a useful library exists to apply regression and other Machine Learning and statisticals tools over the data. It is the so called **sklearn**.\n",
        "\n",
        "This walkthrough will teach you how to use this library in the context of regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi8vCkNF_B3P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "pd.set_option('display.max_columns', None)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32vbaIBt_5KF"
      },
      "source": [
        "## 1. Load the dataset\n",
        "\n",
        "\n",
        "From this library we import the `LinearRegression` module and the different datasets used for our examples. In this section, we will discuss the basics of using the linear model with the weather dataset as example. Then you will be given a task and perform your own linear regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "FRP6bS5fABwY",
        "outputId": "36a5ec11-13f0-4ba0-fe15-6e48459c923d"
      },
      "outputs": [],
      "source": [
        "#Load the dataset\n",
        "url = \"https://media.githubusercontent.com/media/michalis0/Business-Intelligence-and-Analytics/master/data/weather.csv\"\n",
        "weather = pd.read_csv(url).drop_duplicates().dropna()\n",
        "\n",
        "# Display a sample of the data\n",
        "display(weather.head())\n",
        "\n",
        "# Print the data types\n",
        "print(weather.dtypes)\n",
        "print(\"Data matrix shape: \", weather.shape)\n",
        "\n",
        "# Display the columns names\n",
        "print(\"Columns names: \", weather.columns) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "SCCEbriGAmSX",
        "outputId": "befcc89d-918c-4a17-ad94-69b9afc27b5a"
      },
      "outputs": [],
      "source": [
        "# Display correlation of the features for numeric_only features\n",
        "display(weather.corr(numeric_only=True))\n",
        "display(weather.corrwith(weather['Temp3pm'], numeric_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdrFokUIEDci"
      },
      "source": [
        "**Note:** The purpose here is to predict the temperature from other features (like humidity or pression). It is called multivariate linear regression when we use several features as input, univariate otherwise. We will only work with values concerning **3pm** for simplicity.\n",
        "\n",
        "A LinearRegression has this form for one feature: $$ Y_i = w_0 + w_1 X_i + \\epsilon_i$$\n",
        "\n",
        "The betas correspond to the weights of the variables (coefficients). Combined with the features (X matrix) we want to predict the target variable (Y vector). The regression will compute the best value of $w_i$.\n",
        "\n",
        "For now we will focus on a simple linear regression with **one feature variable**. We would like to know if we can use the humity to predict the temperature. Let's separate the feature input from the target output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvHMm6n5Uhef"
      },
      "outputs": [],
      "source": [
        "X = weather[['Humidity3pm']] \n",
        "y = weather[['Temp3pm']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbFaMRiOF-Kr"
      },
      "source": [
        "## 2. Splitting the dataset\n",
        "\n",
        "Sklearn has a very useful module to seprate your dataset in a training and in a testing set. The training set will be used to retreive the best values of the weights according to a combination of input/output while the test set will be used to evaluate/predict our model. Since our model will be trained on particular values we want to test our data on a new set of data (the test set)\n",
        "\n",
        "The test size here is of 20% of the original data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa-wOqD6Cei3"
      },
      "outputs": [],
      "source": [
        "# Split the data into training/testing sets\n",
        "# Split the targets into training/testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUoAlVFvLK8a"
      },
      "source": [
        "**Note:** Generally you should normalize the data right after splitting the datset. The normalization is important here to reduce the variance of our model and get better results. We skip this step for now.\n",
        "\n",
        "The sklearn code uses `MinMaxScaler` module to normalize the data. This estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one.  \n",
        "\n",
        "This is an example of how to use it:\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#Define the scaler\n",
        "scaler = MinMaxScaler()\n",
        "#Fit the scaler\n",
        "scaler.fit(X_train)\n",
        "#Transform the train and the test set\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#These two steps can be merged into one (only for the train set)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFz94n5GIP_T"
      },
      "source": [
        "## 3. Create/Fit the model\n",
        "\n",
        "To predict the target variable we will use a simple linear regression. We can import the module following this path (already done at the beginning of the file):\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qygxTo56HkeH"
      },
      "source": [
        "**Note:** \n",
        "- We create a new LinearRegression model from sklearn\n",
        "- The `fit()` function will fill the linear model from the X_train (feature) and the y_train data (target)\n",
        "- The ``score()``function returns the coefficient of determination R^2 of the prediction. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
        "\n",
        "After fitting the model, we can easily retreive the values of the different beta coefficients (the intercept, and the weight of each feature)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebSpuUsrG-RF",
        "outputId": "1e98127a-3142-4ec3-e5ff-2fa4129d8f64"
      },
      "outputs": [],
      "source": [
        "# There are three steps to model something with sklearn\n",
        "\n",
        "# 1. Set up the model\n",
        "model = LinearRegression(fit_intercept= True)\n",
        "\n",
        "# 2. Use fit\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Check the score/accuracy\n",
        "print(\"R^2 Score of the model: \", round(model.score(X_test, y_test), 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAMS6qKIHC35",
        "outputId": "15501046-d14d-408b-ee8d-36c86636f626"
      },
      "outputs": [],
      "source": [
        "print(\"Intercept: \", model.intercept_[0]) \n",
        "print(\"Features coefficients (weigths): \", model.coef_.flatten()[0])# Get the coefficients, w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3_SgE4nsCIp"
      },
      "source": [
        "**Note:** Considering this linear equation: $ Y_i = w_0 + w_1 X_i + \\epsilon_i$\n",
        "\n",
        "The intercept corresponds to the value of $w_0$. There is only one coefficient,  $w_1$ linked to the humidity feature. Since we have only one value for intercept and coefficients represented as arrays, we apply `flattent()` and `[0]`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkdOvMjoI6mQ"
      },
      "source": [
        "## 4. Prediction/Evaluation\n",
        "\n",
        "Once the model is trained, we can use the ``predict()`` function to predict the values of the test set using `X_test`. This prediction can be compared to the truth value i.e `y_test`.\n",
        "\n",
        "Here is an example for one value prediction. Our model takes a matrix as inputs (X matrix), so even if we want to predict a scalar value we should use `[[...]]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJm-HPRYtGF6",
        "outputId": "28dce2d5-0a04-4532-9fd8-fb9dbe2552aa"
      },
      "outputs": [],
      "source": [
        "print(\"Particular value of humidity: \", X_test.iloc[0].values)\n",
        "\n",
        "# Compute the prediction for input 28 (humidity)\n",
        "prediction = model.predict([[28]])\n",
        "print(\"Prediction/Truth for humidity 28: \", prediction, y_test.iloc[0].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3CbNbOeB6lE"
      },
      "source": [
        "**Note:** Try to use `flatten()` and `[0]` in order to display correctly the above values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the prediction for input 28 (humidity) with flatten\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLEovOE8tGyV"
      },
      "source": [
        "## 5. Evaluation and plotting\n",
        "\n",
        "To better understand why the prediction and actual value are different , we can plot the predictions (line) and the true values from the test set (dots). It is more interesting to predict from the test set because our model is not trained on these values unlike the train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1bnZYPnHK8V"
      },
      "outputs": [],
      "source": [
        "# Model prediction from X_test\n",
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3QWBgialsjhv",
        "outputId": "69b78b00-984b-4f53-c2c2-0167beec118b"
      },
      "outputs": [],
      "source": [
        "# Plot the prediction (the line) over the true value (the dots)\n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.scatter(X_test, y_test)\n",
        "plt.plot(X_test, predictions, 'r')\n",
        "plt.title(\"Humidity against temperature\")\n",
        "plt.xlabel('Humidity')\n",
        "plt.ylabel('Temperature')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asy8tfPuvrKd"
      },
      "source": [
        "We can compare the error of our model by using some metrics like the **MAE (mean absolute error)**, **MSE (mean squared error)** or **R^2** score. Sklearn offers some nice modules to compute these measures. These modules are imported at the begining of the file.\n",
        "\n",
        "These metrics takes the `y_test` values and the `predictions` as arguments. Basically it will analyse how far the prediction is from the true value. Using these metrics is very helpful when looking for the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syKiA49gvpNQ",
        "outputId": "35bab67e-436f-411f-9b26-21ec5850c07e"
      },
      "outputs": [],
      "source": [
        "# Compare the MAE the MSE and the R^2\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)\n",
        "print(\"R^2 %.2f\" % r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVSZVya0iNIy"
      },
      "source": [
        "It is also interesting to compare the result of these metrics between the data from the `test set` and those from the `train set` as it enables you to see whether your model gives a good prediction or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQzowsWVh0ip",
        "outputId": "89de4599-4c48-4341-ba35-b6ab9a2267c9"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_train)\n",
        "mae = mean_absolute_error(y_train, pred)\n",
        "mse = mean_squared_error(y_train, pred)\n",
        "r2 = r2_score(y_train, pred)\n",
        "\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)\n",
        "print(\"R^2 %.2f\" % r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0iXKhoXkUyN"
      },
      "source": [
        "Remember, the higher the R² value, the better the fit. In this case, the testing data yields a higher coefficient. While it might seem a bit counterintuitive\n",
        " Furthermore, the R² calculated with test data is an unbiased measure of your model’s prediction performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0P-xYawgLRH"
      },
      "source": [
        "## 6. Multivariate Regression\n",
        "\n",
        "\n",
        "Here, we will apply the same method to several features. For instance it should be interesting to use these variables: humidity, pressure, sunshine and cloud data to predict the temperature. We continue to work with values concerning 3pm for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTAqzfNAg4Bs"
      },
      "outputs": [],
      "source": [
        "X = weather[['Humidity3pm', 'Cloud3pm', 'Pressure3pm', 'Sunshine']] \n",
        "y = weather[['Temp3pm']]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xPtVWHZMg8sD"
      },
      "source": [
        "### Split the data into a training set and a test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfvjzYBFg4qi"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j_B1LnPqhGz1"
      },
      "source": [
        "### Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-Dxbc6VhF_f",
        "outputId": "96b2fd83-c767-4a84-afce-d007a28a3fbf"
      },
      "outputs": [],
      "source": [
        "# 1. Set up the model\n",
        "model = LinearRegression()\n",
        "# 2. Use fit\n",
        "model.fit(X_train, y_train)\n",
        "# 3. Check the score/accuracy\n",
        "print(\"R^2 Score of the model: \", round(model.score(X_test, y_test), 3))\n",
        "# 4. Print the coefficients of the linear model\n",
        "print(\"Intercept: \", model.intercept_) \n",
        "print(\"Features coefficients (weigths): \", model.coef_)# Get the coefficients, w"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VTTfQrJEhJGA"
      },
      "source": [
        "### Prediction\n",
        "We use the predict() function to predict the values of the test set using X_test.\n",
        "This prediction can be compared to the truth value i.e y_test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HwEZhg8hQ-W",
        "outputId": "a6764ca3-c677-4f31-df49-0368a93eeaaa"
      },
      "outputs": [],
      "source": [
        "print(\"Particular value of ['Humidity3pm', 'Cloud3pm', 'Pressure3pm', 'Sunshine']: \", X_test.iloc[0].values)\n",
        "prediction = model.predict([[ 28.0, 7.0, 1018.2, 7.3]])\n",
        "print(\"Prediction/Truth for [ 28.0, 7.0, 1018.2, 7.3]: \", prediction, y_test.iloc[0].values)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TuY3hTDahTKQ"
      },
      "source": [
        "### Evaluation\n",
        "Lastly, we use the MAE (mean absolute error), MSE (mean squared error) or R^2 score to analyse how far the prediction is from the true value.\n",
        "These  metrics takes the `y_test` values and the `predictions` as arguments. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjdFBojChWDT",
        "outputId": "55656101-690b-4546-d0c6-1e8662b863a9"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(\"MAE %.2f\" % mean_absolute_error(y_test, predictions))\n",
        "print(\"MSE %.2f\" % mean_squared_error(y_test, predictions))\n",
        "print(\"R^2 %.2f\" % r2_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hOMwpd2oSDh",
        "outputId": "2e30dde7-daae-4c4b-831f-e69acd52f01d"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_train)\n",
        "\n",
        "print(\"MAE %.2f\" % mean_absolute_error(y_train, predictions))\n",
        "print(\"MSE %.2f\" % mean_squared_error(y_train, predictions))\n",
        "print(\"R^2 %.2f\" % r2_score(y_train, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "MkwGK6Q5fslb",
        "outputId": "79721bae-a29a-44d4-bbcb-1e7d6602f327"
      },
      "outputs": [],
      "source": [
        "# Arrays to save the different errors\n",
        "train_err = []\n",
        "test_err = []\n",
        "\n",
        "# Iterate over 1, 2, 3 and 4 features\n",
        "for nbr_col in range(1, 5):\n",
        "    # Select the good number of features for X\n",
        "    X_temp = X[X.columns[:nbr_col]]\n",
        "    # Split the dat set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y, test_size=0.2, random_state=10)\n",
        "    # Normalize the data\n",
        "    # Create new scaler from MinMaxScaler()\n",
        "    scaler = MinMaxScaler()\n",
        "    # Fit and transform the original data\n",
        "    scaler.fit(X_train, y_train)\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    # Create the linear model\n",
        "    LR = LinearRegression(fit_intercept=False)\n",
        "    # Fit the linear model\n",
        "    LR.fit(X_train, y_train)\n",
        "    \n",
        "    #Compute and save the mean absolute error fro training and testing set\n",
        "    train_err.append(mean_absolute_error(y_train, LR.predict(X_train)))\n",
        "    test_err.append(mean_absolute_error(y_test, LR.predict(X_test)))\n",
        "\n",
        "# Print the train and the test errors\n",
        "print(\"Train error: \", train_err)\n",
        "print(\"Test error : \", test_err)\n",
        "\n",
        "plt.title(\"Training and test error regarding the number of features\")\n",
        "plt.plot(range(1,5), train_err, label=\"train_error\")\n",
        "plt.plot(range(1,5), test_err, label=\"test_error\")\n",
        "plt.legend(fontsize=10)\n",
        "plt.xlabel(\"Number of features\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## QUIZ ON MOODLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weather.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### QUIZ - QUESTION 1 ON MOODLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "X = weather[['Humidity9am', 'Temp9am', 'Cloud9am', 'WindSpeed9am', 'Sunshine']]\n",
        "y = weather[['Evaporation']]\n",
        "\n",
        "# Split the data set using a test size of 0.2 and a random state of 10\n",
        "# YOUR CODE HERE\n",
        "X_train, X_test, y_train, y_test = ...\n",
        "\n",
        "# DO NOT NORMALIZE THE DATA\n",
        "\n",
        "# Create the linear model\n",
        "# YOUR CODE HERE\n",
        "model = ...\n",
        "\n",
        "# Fit the linear model\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Compute the prediction\n",
        "# YOUR CODE HERE\n",
        "predictions = ...\n",
        "\n",
        "# Compute the mean absolute error\n",
        "# YOUR CODE HERE\n",
        "\n",
        "print(\"Intercept: \", model.intercept_) \n",
        "print(\"Features coefficients (weigths): \", model.coef_)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### QUIZ - QUESTION 2 ON MOODLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "X = weather[['Humidity9am', 'Temp9am', 'Cloud9am', 'WindSpeed9am', 'Sunshine']]\n",
        "y = weather[['Evaporation']]\n",
        "\n",
        "# Split the data set using a test size of 0.2 and a random state of 10\n",
        "X_train, X_test, y_train, y_test = ...\n",
        "\n",
        "\n",
        "# Normalize the data using the Normalizer\n",
        "# Create new scaler from Normalizer()\n",
        "scaler = Normalizer()\n",
        "# Fit and transform the original data\n",
        "scaler.fit(X_train, y_train)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create the linear model\n",
        "# YOUR CODE HERE\n",
        "model = ...\n",
        "\n",
        "# Fit the linear model\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Compute the prediction\n",
        "# YOUR CODE HERE\n",
        "predictions = ...\n",
        "\n",
        "# Compute the R^2\n",
        "r2 = ...\n",
        "\n",
        "print(\"Intercept: \", model.intercept_) \n",
        "print(\"Features coefficients (weigths): \", model.coef_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Walkthrough_Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0cc462c96df3621bcc58e01fadcdf9264a069c5c4bbf07201077bb349d3c6bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
