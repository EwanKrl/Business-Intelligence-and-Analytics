{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/Business-Intelligence-and-Analytics/blob/master/labs/08%20-%20Regression2/walkthrough/walkthrough_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u461z_Wk-K-P"
      },
      "source": [
        "<h1 align=\"center\"> WALKTHROUGH 8</h1>\n",
        "\n",
        "<div>\n",
        "<td> \n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Logo_Universit%C3%A9_de_Lausanne.svg/2000px-Logo_Universit%C3%A9_de_Lausanne.svg.png\" style=\"padding-right:10px;width:240px;float:left\"/></td>\n",
        "<h2 style=\"white-space: nowrap\">Business Intelligence and Analytics</h2></td>\n",
        "<hr style=\"clear:both\">\n",
        "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
        "\n",
        "</div>\n",
        "\n",
        "This week we continue working on regression. Diving into more specific methods, we will show you how to choose the number of parameters, cross validation and 1-hot/label encoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEjK31c_tCl1"
      },
      "source": [
        "# REGRESSION WITH CATEGORICAL VARIABLES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi8vCkNF_B3P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import seaborn as sns\n",
        "import statistics\n",
        "%matplotlib inline\n",
        "sns.set(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32vbaIBt_5KF"
      },
      "source": [
        "## LOAD THE DATASET\n",
        "\n",
        "The Dataset we will be working on was extracted and modified from [Kaggle](https://www.kaggle.com/mohansacharya/graduate-admissions). It gives us various information concerning students and their chances of admission.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "FRP6bS5fABwY",
        "outputId": "8be5b102-21eb-48be-a2d7-a4a08643537d"
      },
      "outputs": [],
      "source": [
        "#Load the dataset\n",
        "url = 'https://media.githubusercontent.com/media/michalis0/Business-Intelligence-and-Analytics/master/data/Admissions_prediction.csv'\n",
        "GAD = pd.read_csv(url, sep = \";\", index_col= 'Serial No.').drop_duplicates() #Graduate Admissions Data\n",
        "\n",
        "display(GAD.head())\n",
        "print(GAD.dtypes)\n",
        "print(\"Data matrix shape: \", GAD.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRv1WpGd_fXY"
      },
      "source": [
        "An overview of the columns:\n",
        "\n",
        " \n",
        " * `GRE Score`: GRE is a standardized admission test (out of 340)\n",
        " * `TOEFL Score`: English knowledge (out of 120)\n",
        " * `SOP`: Standard of Purpose (out of 5)\n",
        " * `LOR`: Letter of Recomendation (out of 5)\n",
        " * `CGPA`: College GPA (out of 10)\n",
        " * `RESEARCH`: Whether the applicant did research or not\n",
        " \n",
        " We will try to predict the chance of admit with the other variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU0MR4S4_9k9"
      },
      "source": [
        "## HANDLING CATEGORICAL VARIABLES FOR REGRESSION\n",
        "First, let's focus on the `Research` column. The applicant was either active in research, or he was not. There are therefore only 2 possible values, hence we will assign 1 for YES and 0 for NO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "M2kOpYqBAVOW",
        "outputId": "60f3f47f-8062-48f2-d0e0-dbb21c5d29ac"
      },
      "outputs": [],
      "source": [
        "GAD['Research'] = GAD['Research'].replace(['NO', 'YES'], [0,1])\n",
        "display(GAD.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qdFhlJ_psym"
      },
      "source": [
        "Here let's get a quick overview of the existing correlations between our variables using a heatmap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "nERSyNFIdKYU",
        "outputId": "8fe1b3ed-351f-47fa-aeeb-5562293b2bb5"
      },
      "outputs": [],
      "source": [
        "d = sns.heatmap(GAD.corr(numeric_only=True), annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySZ47n4bO6J9"
      },
      "outputs": [],
      "source": [
        "# We want to predict the chance of admission\n",
        "y = GAD[['Chance of Admit']]\n",
        "\n",
        "# With the help of the other columns\n",
        "X = GAD.drop('Chance of Admit', axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmtpafMDSjep"
      },
      "source": [
        "Now we need to handle the `University Ranking`. \n",
        "We will do both, one-hot and label encoding.\n",
        "For label encoding, we can use Sklearn's LabelEncoder() function. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMz58tDKSliV"
      },
      "outputs": [],
      "source": [
        "# Label encoder\n",
        "X_label = X.apply(LabelEncoder().fit_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "0wVLnTrdqf88",
        "outputId": "4d9f8487-59d7-414c-d3c4-bb956a5ce5fb"
      },
      "outputs": [],
      "source": [
        "display(X_label.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlj_DnDMqr_z"
      },
      "source": [
        "For one hot encoding we use pandas get dummy function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "IyuTZwch3Vbs",
        "outputId": "34debbee-4f36-4097-c912-95118d1ac8f4"
      },
      "outputs": [],
      "source": [
        "# 1-hot encoding\n",
        "\n",
        "# We create a DF with Dummy variables\n",
        "dummies = pd.get_dummies(GAD[\"University Rating\"])\n",
        "X_hot = pd.concat([GAD, dummies], axis = 1)\n",
        "\n",
        "# We drop the Rating column \n",
        "del X_hot[\"University Rating\"]\n",
        "del X_hot[\"Chance of Admit\"]\n",
        "\n",
        "# Have a look at what dummies actually looks like\n",
        "dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "QNlYISNDqWc7",
        "outputId": "2052dbf2-14b2-4e39-d03b-25a3349dcdfa"
      },
      "outputs": [],
      "source": [
        "display(X_hot.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQK3FiQe-lll"
      },
      "source": [
        "We will now build two models, one for 1-hot encoding and one for label encoding.\n",
        "Let's start with label encoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6IAkPe5_GlF",
        "outputId": "0aa1f3ad-c7b1-4eca-9800-eb5dacf2fd38"
      },
      "outputs": [],
      "source": [
        "# Split Dataset\n",
        "X_train_lab, X_test_lab, y_train_lab, y_test_lab = train_test_split(X_label, y, test_size=0.2, random_state=0, shuffle=True)\n",
        "\n",
        "# Fit the model\n",
        "model_lab = LinearRegression()\n",
        "model_lab.fit(X_train_lab, y_train_lab)\n",
        "\n",
        "# Calculate R2\n",
        "lab_r2 = round(model_lab.score(X_train_lab, y_train_lab), 4)\n",
        "print(\"R^2 of train set using label encoding: \", lab_r2 )\n",
        "\n",
        "# Calculate Scores on Test-Set\n",
        "label_predictions = model_lab.predict(X_test_lab)\n",
        "lab_mae = mean_absolute_error(y_test_lab, label_predictions)\n",
        "lab_mse = mean_squared_error(y_test_lab, label_predictions)\n",
        "lab_r2_test = r2_score(y_test_lab, label_predictions)\n",
        "\n",
        "print(\"MAE LAB %.2f\" % lab_mae)\n",
        "print(\"MSE LAB %.2f\" % lab_mse)\n",
        "print(\"R^2 score LAB %.4f\" % lab_r2_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CdawFAZDMgM"
      },
      "source": [
        "And continue with 1-hot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVFRDpP9-1VQ",
        "outputId": "3a93e0bb-f6f1-4968-c094-4dada0942e3d"
      },
      "outputs": [],
      "source": [
        "# Split Dataset\n",
        "X_train_hot, X_test_hot, y_train_hot, y_test_hot = train_test_split(X_hot, y, test_size=0.2, random_state=0, shuffle=True)\n",
        "\n",
        "# Fit the model\n",
        "model_hot = LinearRegression()\n",
        "model_hot.fit(X_train_hot, y_train_hot)\n",
        "\n",
        "# Calculate R2\n",
        "hot_r2 = round(model_hot.score(X_train_hot, y_train_hot), 4)\n",
        "print(\"R^2 Train Score using 1-hot encoding : \", hot_r2 )\n",
        "\n",
        "# Calculate Scores on Test-Set\n",
        "hot_predictions = model_hot.predict(X_test_hot)\n",
        "hot_mae = mean_absolute_error(y_test_hot, hot_predictions)\n",
        "hot_mse = mean_squared_error(y_test_hot, hot_predictions)\n",
        "hot_r2_test = r2_score(y_test_hot, hot_predictions)\n",
        "\n",
        "print(\"MAE HOT %.2f\" % hot_mae)\n",
        "print(\"MSE HOT %.2f\" % hot_mse)\n",
        "print(\"R^2 score HOT %.4f\" % hot_r2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-pi4KJa_x39",
        "outputId": "9e99eb03-f1b1-42f8-c44f-bb3801ef4ebe"
      },
      "outputs": [],
      "source": [
        "print(\"The 1-hot encoding method yields an R^2 {}% higher than using label encoding for the train set.\".format(round((hot_r2/lab_r2 -1)*100, 3)))\n",
        "\n",
        "print(\"The 1-hot encoding method yields an R^2 {}% higher than using label encoding for the test set.\".format(round((hot_r2_test/lab_r2_test -1)*100, 3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC7JH-e0Dd4d"
      },
      "source": [
        "Have a look at how the coefficients change for each method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAMS6qKIHC35",
        "outputId": "288b9fb1-9f9c-4bd2-ca6c-053b432cf651"
      },
      "outputs": [],
      "source": [
        "print(\"Intercept: \", model_hot.intercept_[0]) \n",
        "print(\"Intercept: \", model_lab.intercept_[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEJzhlGNIR0E",
        "outputId": "55bb1aeb-33d0-4e9a-b502-5cec4c20f275"
      },
      "outputs": [],
      "source": [
        "weights_hot = model_hot.coef_.flatten()\n",
        "weights_lab = model_lab.coef_.flatten()\n",
        "\n",
        "print(\"Features coefficients for HOT (weigths): \", model_hot.coef_)\n",
        "print(\"Features coefficients for LAB (weigths): \", model_lab.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmwVCD3rWxfT"
      },
      "source": [
        "# POLYNOMIAL LINEAR REGRESSION\n",
        "We will now have a look at another model. We are going to use `Advertisement` data we previously used. The task is to figure out how different means of advertisement influence the amount of sales of a product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s-2cmk3BXdcJ",
        "outputId": "03ea0daa-2d1d-49e7-9905-77375fae4dec"
      },
      "outputs": [],
      "source": [
        "ad_df = pd.read_csv('https://media.githubusercontent.com/media/michalis0/Business-Intelligence-and-Analytics/master/data/Advertising.csv')\n",
        "# view the first 5 rows \n",
        "ad_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4m4OAEl1X2f5"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for the regression\n",
        "y = ad_df[\"Sales\"]\n",
        "X = ad_df.drop(\"Sales\", axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dB3hlTFYgOx",
        "outputId": "dc17bd1f-3c27-4689-f053-2206b25f7bff"
      },
      "outputs": [],
      "source": [
        "# First let's go for a linear multivariate regression\n",
        "# You should know the drill by now\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, shuffle=True)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Performance metrics\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print(\"Test scores: \")\n",
        "print(\"MAE %.2f\" % mae)\n",
        "print(\"MSE %.2f\" % mse)\n",
        "print(\"R^2 %.2f\" % r2)\n",
        "\n",
        "print(\"Train metrics\")\n",
        "print(\"params: \", model.coef_)\n",
        "print(\"constant: \", model.intercept_)\n",
        "print(\"R^2 score: \", model.score(X, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vat_JVqHsm7B"
      },
      "source": [
        "Using polynomial regression enables you to predict the best fit line that follows the pattern(curve) of the data. It tends to increase the performance of the model. The function PolynomialFeatures generates a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2]. Let's try it on our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkr3ptZwaVa4",
        "outputId": "0fb2ef73-b916-4607-ae7d-521a7ffa6adb"
      },
      "outputs": [],
      "source": [
        "# Polynomial regression\n",
        "poly = PolynomialFeatures(2)\n",
        "X = np.array(ad_df[[\"TV\", \"Radio\"]])\n",
        "y = np.array(ad_df[\"Sales\"])\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "LR = LinearRegression(fit_intercept=False) # We don't need fit intercept sice polynomial features function add a column of ones to the data \n",
        "LR.fit(X_poly, y)\n",
        "print(\"params: \", LR.coef_)\n",
        "print(\"R^2 score: \", LR.score(X_poly, y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAXvuEElrTSF"
      },
      "source": [
        "## OVERFITTING\n",
        "Beware, adding too many features may cause overfitting.\n",
        "Remember that overfitting is is the tendency of data mining procedures to tailor models to the training data, at the expense of generalization to previously unseen data points. We want to avoid this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "-_KqypF0rV_7",
        "outputId": "3a41fc23-acaf-46f9-9620-7fb73c9a1c90"
      },
      "outputs": [],
      "source": [
        "train_err = []\n",
        "test_err = []\n",
        "for f in range(1,8):\n",
        "    poly = PolynomialFeatures(f)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=12)\n",
        "    LR = LinearRegression(fit_intercept=False)\n",
        "    LR.fit(X_train, y_train)\n",
        "    train_err.append(mean_squared_error(y_train, LR.predict(X_train)))\n",
        "    test_err.append(mean_squared_error(y_test, LR.predict(X_test)))\n",
        "\n",
        "\n",
        "fig=plt.figure(figsize=(11,7))\n",
        "plt.plot(range(1,8), train_err, label=\"train_error\")\n",
        "plt.plot(range(1,8), test_err, label=\"test_error\")\n",
        "plt.legend(fontsize=10)\n",
        "plt.xlabel(\"polynomial degree\")\n",
        "dummy = plt.ylabel(\"error\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_cRswO1mo1j",
        "outputId": "59bc36d8-eaf8-4ba4-e5df-25a06d0a3301"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "y = ad_df[\"Sales\"]\n",
        "X = ad_df.drop(\"Sales\", axis = 1)\n",
        "\n",
        "kf = KFold(n_splits = 10, random_state = None)\n",
        "model = LinearRegression()\n",
        "\n",
        "mae_cumm = []\n",
        "mse_cumm = []\n",
        "r2_cumm = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "  \n",
        "  X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "  predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "  mae = mean_absolute_error(y_test, predictions)\n",
        "  mse = mean_squared_error(y_test, predictions)\n",
        "  r2 = r2_score(y_test, predictions)\n",
        "\n",
        "  mae_cumm.append(mae)\n",
        "  mse_cumm.append(mse)\n",
        "  r2_cumm.append(r2)\n",
        "\n",
        "  \n",
        "mean_mae = sum(mae_cumm)/len(mae_cumm)\n",
        "mean_mse = sum(mse_cumm)/len(mse_cumm)\n",
        "mean_r2 = sum(r2_cumm)/len(r2_cumm)\n",
        "\n",
        "print(\"The mean absolute error of all our folds was: \",round(mean_mae, 3))\n",
        "print(\"The mean squared error of all our folds was: \", round(mean_mse, 3))\n",
        "print(\"The mean accuracy of all our folds was: \", round(mean_r2, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii28pGKIygC-"
      },
      "source": [
        "And for higher order polynomial regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "akT_H53UysOx",
        "outputId": "6f7645f6-9a48-4069-fa2a-0a9a3d77cd40"
      },
      "outputs": [],
      "source": [
        "train_err = []\n",
        "test_err = []\n",
        "\n",
        "y = ad_df[\"Sales\"]\n",
        "X = ad_df.drop(\"Sales\", axis = 1)\n",
        "\n",
        "kf = KFold(n_splits = 10, random_state = None)\n",
        "model = LinearRegression(fit_intercept = False)\n",
        "\n",
        "for f in range(1,7):\n",
        "  train = []\n",
        "  test = []\n",
        "  for train_index, test_index in kf.split(X):\n",
        "    poly = PolynomialFeatures(f)\n",
        "    X_poly = poly.fit_transform(X)\n",
        "    X_train, X_test = X_poly[train_index,:], X_poly[test_index,:]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    train.append(mean_squared_error(y_train, model.predict(X_train)))\n",
        "    test.append(mean_squared_error(y_test, model.predict(X_test)))\n",
        "\n",
        "  train_err.append(statistics.mean(train))\n",
        "  test_err.append(statistics.mean(test))\n",
        "\n",
        "fig=plt.figure(figsize=(11,7))\n",
        "plt.plot(range(1,7), train_err, label=\"train_error\")\n",
        "plt.plot(range(1,7), test_err, label=\"test_error\")\n",
        "plt.legend(fontsize=10)\n",
        "plt.xlabel(\"polynomial degree\")\n",
        "plt.ylabel(\"error\")\n",
        "print(train_err)\n",
        "print(test_err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZorP9fsmDmF"
      },
      "source": [
        "# Moodle Quiz\n",
        "In the two following questions, we are going to use the dataset \"wages.csv\" that contains data regarding individuals' yearly wages and potential explanatory variables, such as age, education, sex and ethnicity.\n",
        "\n",
        "We are going to conduct a simple analysis of the way these factors may influence earnings.\n",
        "\n",
        "> In the **first question**, we will one-hot encode the dataset and use it for a multivariate linear regression.\n",
        "\n",
        "> In the **second question**, we will look at a polynomial regression and how it can lead to overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEcY91hBmMcD"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Please follow the instructions in the cells. You will have to find the estimated effect of being hispanic on one's yearly earnings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8VZ_SYcomEM8",
        "outputId": "4e910efa-4ec8-49a3-c516-b8b290a6b002"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "wage = pd.read_csv(\"https://media.githubusercontent.com/media/michalis0/Business-Intelligence-and-Analytics/master/data/wages.csv\")\n",
        "display(wage.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRCz6XefmVLc"
      },
      "outputs": [],
      "source": [
        "# Store the dependent variable \"earn\" in its own data Series.\n",
        "y = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCZpbvtVmWFT"
      },
      "outputs": [],
      "source": [
        "# Replace in the column \"sex\" : \"male\" by 0 and \"female\" by 1\n",
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49nU-tnxmhDT"
      },
      "outputs": [],
      "source": [
        "# 1-hot encode the \"race\" column to obtain a usable \"X\" DF.\n",
        "\n",
        "# Create a DataFrame with dummy variables\n",
        "dummies = ...\n",
        "\n",
        "# Concatenate the dummy DF with the wage DF along axis=1\n",
        "X = ...\n",
        "\n",
        "# Drop our predicted variable, \"earn\"\n",
        "\n",
        "# Drop the un-encoded variable, \"race\"\n",
        "\n",
        "# Uncomment the following cell to check your 1-hot encoded dataset\n",
        "# display(X.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rvv6hiWFmxqA"
      },
      "outputs": [],
      "source": [
        "# Do the train/test split with a test size of 0.2 and a random state of 44\n",
        "\n",
        "\n",
        "# Initialize and fit the model with the training data.\n",
        "model = ...\n",
        "\n",
        "# What is the coefficient of being hispanic on earnings in this trained model? (all else equal)\n",
        "hispanic = ...\n",
        "\n",
        "# Uncomment the following cell to get the answer\n",
        "# print(\"Being hispanic leads to earnings higher/lower by %.2f\" % hispanic)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MuaCgdicnMAH"
      },
      "source": [
        "## QUESTION 2\n",
        "In this question, we will use the same dataset as before. We will however focus on the three numerical variables: height, education and age. <br>\n",
        "The goal is to see at what degree of polynomial regression the test error explodes: this will be a situation of overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mzcVHtzHnMWq",
        "outputId": "51c6b5ac-6247-47ce-9ac0-030448e38184"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "wage = pd.read_csv(\"https://media.githubusercontent.com/media/michalis0/Business-Intelligence-and-Analytics/master/data/wages.csv\")\n",
        "display(wage.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poXS57fhnOnK"
      },
      "outputs": [],
      "source": [
        "# Store the \"earn\" column in a \"y\" Series.\n",
        "y = ...\n",
        "\n",
        "# Keep only three columns: \"height\", \"ed\" and \"age\"\n",
        "X = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCvmrEEHnXF0"
      },
      "outputs": [],
      "source": [
        "# Find when there is overfitting by using iterations of the PolynomialFeatures model.\n",
        "# (Important!) The test_size is 0.25 and the random_state is 44. \n",
        "\n",
        "# Hint: the range to look at is between 1 and 10\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# Plot the resulting test and training errors. Remember, the range is between 1 and 10. Use log scale for the y-axis if you want to see the difference better.\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc9INbMznaJD"
      },
      "source": [
        "What is the **maximum** value of polynomial features that doesn't lead to overfitting?\n",
        "\n",
        "(i.e., the test error explodes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0cc462c96df3621bcc58e01fadcdf9264a069c5c4bbf07201077bb349d3c6bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
